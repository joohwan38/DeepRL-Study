{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "planegame_RL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1u42PkN7GL-w5Th6yhSA58T9zC2CLnVcV",
      "authorship_tag": "ABX9TyOUbRAArRn5z6QxZOPZjVZf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joohwan38/DeepRL-Study/blob/main/planegame_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK-5tkrHkvui",
        "outputId": "36bc566f-0355-4c2c-f6c5-fbf37bb961c1"
      },
      "source": [
        "!pip install stable_baselines3\n",
        "!pip install gym\n",
        "!pip install pygame"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (0.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.9.0+cu102)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->stable_baselines3) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->stable_baselines3) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->stable_baselines3) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->stable_baselines3) (3.7.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->stable_baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable_baselines3) (2018.9)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6M3gmZukjXF"
      },
      "source": [
        "#import GYM stuff\n",
        "import gym \n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
        "\n",
        "#import helpers\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "#import Stable baselines stuff\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "#import pygame\n",
        "import pygame\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# pygame.quit()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psurcvtq46CC"
      },
      "source": [
        "향후 과제 \n",
        "\n",
        "1. cnn\n",
        ": screen 을 설정하면 파이게임 자체 기능으로  width * height * color(RGB) 의 3차원 numpy 배열로 추출 가능 예시) 500 * 900 * 3 = 45000*3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3sxSSzpkoWq"
      },
      "source": [
        "pygame.init()\n",
        "#오브젝트 좌표, 이속, 사이즈 초기값 세팅\n",
        "class obj:\n",
        "    def __init__(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        self.move = 0\n",
        "    def put_img(self, a, b):\n",
        "        self.sx, self.sy = a, b\n",
        "\n",
        "#충돌 판정 (y/n)\n",
        "def crash(a, b):\n",
        "    if (a.x-b.sx <= b.x) and (b.x <= a.x+a.sx):\n",
        "        if (a.y-b.sy <= b.y) and (b.y <= a.y+a.sy):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "#커스텀 환경 세팅)\n",
        "\n",
        "class PlaneEnv(Env):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Actions 조작의 범위 설정\n",
        "        self.action_space = Discrete(3) \n",
        "        # 옵저베이션 설정 (x축, y축)\n",
        "        self.observation_space = MultiDiscrete([500, 500, 900, 500, 900, 500, 900, 500, 900, 500, 900])\n",
        "        # 시작 값 설정 (all zero)\n",
        "        self.state = np.zeros(11, dtype=int)\n",
        "        \n",
        "        self.ss = obj()\n",
        "        #비행선 사이즈\n",
        "        self.ss.put_img(50, 60)\n",
        "        \n",
        "        #비행선 시작 좌표\n",
        "        self.ss.x = 205 #round(size[0]/2 - self.ss.sx/2)\n",
        "        self.ss.y = 825 #size[1] -self.ss.sy - 15\n",
        "        self.ss.move = 20\n",
        "        \n",
        "        \n",
        "# 1프레임마다 일어날 일돌 \n",
        "    def step(self, action):\n",
        "        global done\n",
        "        \n",
        "        #프레임당 생존 시 리워드 2점 지급 (삭제) (기본 리워드 0점이며, +- 를 통해 최종 산출)\n",
        "        #reward =2\n",
        "        reward = 0\n",
        "\n",
        "        #액션에 따른 비행선의 x좌표 변경 0 왼쪽 / 1 오른쪽 / 2 제자리 - 화면 가장자리를 넘어가지 않게 설정\n",
        "        if action ==0:\n",
        "            self.ss.x -= self.ss.move\n",
        "            if self.ss.x <= 50:\n",
        "                self.ss.x = 50\n",
        "        elif action ==1:\n",
        "            self.ss.x += self.ss.move\n",
        "            if self.ss.x >= 425:\n",
        "                self.ss.x = 425\n",
        "        elif action ==2:\n",
        "            pass\n",
        "\n",
        "        #랜덤하게 적 비행체 생성 (프레임당 10% 확률로 생성)\n",
        "        if random.random() > 0.90:\n",
        "            aa = obj()\n",
        "            aa.put_img(40, 40)\n",
        "\n",
        "            # 5배의 확률로 내가 멈춰있는 x좌표 위에 적군 생성 / 나머지는 전역 생성\n",
        "            mylist = [self.ss.x, random.randrange(0,478)]\n",
        "            aa.x = random.choices(mylist, weights = [10, 2], k = 1)[0]\n",
        "            aa.y = 10\n",
        "            aa.move = 25\n",
        "            a_list.append(aa)\n",
        "\n",
        "        #레이더 설정    \n",
        "        for i in range(len(a_list)):\n",
        "            #y 좌표가 나보다 낮아지면 레이더 계산하지 않음\n",
        "            if a_list[i].y < 825:\n",
        "                pass\n",
        "            #비행체의 중심부 - 적비행체 중심부간 유클리디안 거리가 100픽셀 보다 낮을때 레이더 발동\n",
        "            #레이더에 걸리면, 100 나누기 둘사이 거리의 10분의 1만큼 감점 수식 (100 / (distance / 10)) - 0으로 나뉘는 문제 발생 (거리가 0이 될수는 없는데, 간헐적으로 오류처럼 발생)\n",
        "            elif (abs(self.ss.x+25 - a_list[i].x+20) * abs(self.ss.y+30 - a_list[i].y+20))**(1/2) < 100:\n",
        "                if (abs(self.ss.x+25 - a_list[i].x+20) * abs(self.ss.y+30 - a_list[i].y+20))**(1/2) > 0:\n",
        "                    reward -= round(100 / (((abs(self.ss.x+25 - a_list[i].x+20) * abs(self.ss.y+30 - a_list[i].y+20))**(1/2))/10))\n",
        "                else :\n",
        "                    reward -= round(100 / (((abs(self.ss.x+25 - a_list[i].x+20) * abs(self.ss.y+30 - a_list[i].y+20))**(1/2)+10)/10))\n",
        "            elif (abs(self.ss.x+25 - a_list[i].x+20) * abs(self.ss.y+30 - a_list[i].y+20))**(1/2) < 450:\n",
        "                #거리가 100보다 크고 450보다 작은때에는 2점을 받는다. 적군이 없거나, 아주 멀리 있을때 취하는 액션이 꽁으로 reward를 받는 것을 학습하는것을 막기 위해\n",
        "                reward = 2\n",
        "\n",
        "        #충돌 시 감점 로직    \n",
        "        for i in range(len(a_list)):\n",
        "            a = a_list[i]\n",
        "            if crash(a, self.ss) == True:\n",
        "                done=True\n",
        "                reward -=100\n",
        "        \n",
        "        # 현재 프레임의 옵저베이션값 리턴 (state)\n",
        "        self.state[0] = self.ss.x\n",
        "        for i in range(len(a_list[:(len(self.state)-1)//2])):\n",
        "            self.state[2*i+1] = a_list[i].x\n",
        "            self.state[2*i+2] = a_list[i].y\n",
        "\n",
        "        #미사일의 좌표를 화면을 넘어가면 트래킹 하지 않게 삭제해주기\n",
        "        \n",
        "        d_list = []\n",
        "        for i in range(len(a_list)):\n",
        "            ea = a_list[i]\n",
        "            ea.y += ea.move\n",
        "            if ea.y >= size[1]:\n",
        "                d_list.append(i)\n",
        "        #미사일이 화면 밖으로 넘어갔다는 것은 회피를 위미하므로, 회피시 리워드 지급하기\n",
        "                reward +=30\n",
        "        for d in d_list:\n",
        "            del a_list[d]\n",
        "        \n",
        "        info = {}\n",
        "        \n",
        "        # Return step information\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        pass\n",
        "    \n",
        "    #게임리셋 (환경 초기화, 비행체 시작위치 초기화)\n",
        "    #적 비행체는 초기화 하지 않아도 됨 (프레임에서 생성하기 때문에 환경초기화 만으로 전체초기화 됨)\n",
        "    def reset(self):\n",
        "        # Reset shower temperature\n",
        "        self.state = np.zeros(11, dtype=int)\n",
        "        # Set shower length\n",
        "        self.ss.x = 205 #round(size[0]/2 - self.ss.sx/2)\n",
        "        self.ss.y = 825 #size[1] -self.ss.sy - 15\n",
        "        \n",
        "        return self.state"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doWurlgFlOiO"
      },
      "source": [
        "#환경 불러오기\n",
        "size = [500, 900]\n",
        "\n",
        "env=PlaneEnv()\n",
        "\n",
        "a_list=[]\n",
        "d_list=[]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dy8H9U-lR46",
        "outputId": "f2d66695-9df5-4df4-8238-4c6a9d1cc4b9"
      },
      "source": [
        "#랜덤 액션 테스트 10회\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    reward = 0\n",
        "    a_list=[]\n",
        "    d_list=[]\n",
        "    \n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "#         print(action, n_state, score, done)\n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "env.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:-485\n",
            "Episode:2 Score:-459\n",
            "Episode:3 Score:-400\n",
            "Episode:4 Score:-443\n",
            "Episode:5 Score:-416\n",
            "Episode:6 Score:-840\n",
            "Episode:7 Score:-537\n",
            "Episode:8 Score:-400\n",
            "Episode:9 Score:-400\n",
            "Episode:10 Score:-458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBj0rVM9lTlH"
      },
      "source": [
        "#모델 트레이닝\n",
        "log_path = os.path.join('Training', 'Logs')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGwb0znMlVs5",
        "outputId": "9f79a074-cf0c-4575-f4ce-562ebe998032"
      },
      "source": [
        "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "ZYRW71yMlXHL",
        "outputId": "dd066caa-6488-4f05-b1bd-693196b3375b"
      },
      "source": [
        "#콜백 하지 않기\n",
        "model.learn(total_timesteps=500000)#, callback=eval_callback)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0019292cd8e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#콜백 하지 않기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, callback=eval_callback)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6P7LIVcvFa9"
      },
      "source": [
        "#모델 저장하기\n",
        "plane_path = os.path.join('Training', 'Saved Models', 'evolution_10M_PPO')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a7eu8i6ldbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e328f8aa-864d-4477-8945-3c6ee458838c"
      },
      "source": [
        "model.save(plane_path)\n",
        "evaluate_policy(model, env, n_eval_episodes=100, render=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'Training/Saved Models' does not exist. Will create it.\n",
            "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n",
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-252.52, 263.52899195344713)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwFq5Uwgl280"
      },
      "source": [
        "# training_log_path = os.path.join(log_path, 'PPO_20')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqd-TPWepGOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699b1ba0-9a36-4bf2-f922-c4176340faf4"
      },
      "source": [
        "#모델 불러오기\n",
        "model = PPO.load(plane_path, env)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP0AWJtWpRJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc34195e-77ec-4815-9993-d80e3fca2609"
      },
      "source": [
        "#어떤식으로 움직이고, 어떤 값을 리턴하는지 확인해보기 (랜더링 없이)\n",
        "\n",
        "s_list=[]\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    reward = 0\n",
        "    a_list=[]\n",
        "    d_list=[]\n",
        "    \n",
        "    k=0\n",
        "    while not done:\n",
        "        k+=1\n",
        "        env.render()\n",
        "        action, _states = model.predict(obs)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "        if k %10 == 0:\n",
        "          print(obs, action, score)\n",
        "    s_list.append(k)\n",
        "    print('Episode:{} Score:{} Total Steps:{}'.format(episode, score, k))\n",
        "print('mean K:{}'.format(np.mean(s_list)))\n",
        "env.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[405 225 235   0   0   0   0   0   0   0   0] 1 20\n",
            "[425 225 485 425 235 425 185 425  60   0   0] 1 40\n",
            "[425 225 735 425 485 425 435 425 310 425 210] 1 60\n",
            "[425 425 735 425 685 425 560 425 460 177 435] 1 64\n",
            "Episode:1 Score:-332 Total Steps:42\n",
            "[405   0   0   0   0   0   0   0   0   0   0] 1 20\n",
            "[425   0   0   0   0   0   0   0   0   0   0] 1 40\n",
            "[425 425 135   0   0   0   0   0   0   0   0] 1 60\n",
            "[425 425 385 425 235   0   0   0   0   0   0] 1 80\n",
            "[425 425 635 425 485   0   0   0   0   0   0] 1 100\n",
            "Episode:2 Score:-288 Total Steps:56\n",
            "[405   0   0   0   0   0   0   0   0   0   0] 1 20\n",
            "[425 425 235 138 135 425  60   0   0   0   0] 1 40\n",
            "[425 425 485 138 385 425 310   0   0   0   0] 1 60\n",
            "[425 425 735 138 635 425 560   0   0   0   0] 1 80\n",
            "Episode:3 Score:-316 Total Steps:42\n",
            "[405 365  60   0   0   0   0   0   0   0   0] 1 20\n",
            "[425 365 310   0   0   0   0   0   0   0   0] 1 40\n",
            "[425 365 560 425  10   0   0   0   0   0   0] 1 60\n",
            "[425 365 810 425 260 425 210   0   0   0   0] 1 80\n",
            "[425 425 510 425 460 425 135 425  60   0   0] 1 59\n",
            "[425 425 760 425 710 425 385 425 310   0   0] 1 79\n",
            "Episode:4 Score:-319 Total Steps:61\n",
            "[405 265 185   0   0   0   0   0   0   0   0] 1 20\n",
            "[425 265 435   0   0   0   0   0   0   0   0] 1 40\n",
            "[425 265 685  88  60   0   0   0   0   0   0] 1 60\n",
            "[425  88 310  88 260   0   0   0   0   0   0] 1 59\n",
            "[425  88 560  88 260   0   0   0   0   0   0] 1 79\n",
            "[425  88 810 425 235 425 210 425  85   0   0] 1 99\n",
            "[425 425 485 425 460 425 335 425 185 425  10] 1 120\n",
            "[425 425 735 425 710 425 585 425 435 425  10] 1 140\n",
            "Episode:5 Score:-256 Total Steps:82\n",
            "[405  93 185   0   0   0   0   0   0   0   0] 1 20\n",
            "[425  93 435 276 110   0   0   0   0   0   0] 1 40\n",
            "[425  93 685 276 360 425 160  31  60   0   0] 1 60\n",
            "[425 276 610 425 410  31 310 425 135 425 110] 1 81\n",
            "[405 276 860 425 660  31 560 425 385 425 360] 0 70\n",
            "Episode:6 Score:-313 Total Steps:55\n",
            "[405 265 185 305 135   0   0   0   0   0   0] 1 20\n",
            "[425 265 435 305 385 425 185   0   0   0   0] 1 40\n",
            "[425 265 685 305 635 425 435   0   0   0   0] 1 60\n",
            "[425 305 885 425 685 425 110 425  60   0   0] 1 32\n",
            "Episode:7 Score:-360 Total Steps:44\n",
            "[405   0   0   0   0   0   0   0   0   0   0] 1 20\n",
            "[425   0   0   0   0   0   0   0   0   0   0] 1 40\n",
            "[425 154 235 425 210   0   0   0   0   0   0] 1 60\n",
            "[425 154 485 425 460 425 235 314 110   0   0] 1 80\n",
            "[425 154 735 425 710 425 485 314 360 425 210] 1 100\n",
            "Episode:8 Score:-294 Total Steps:53\n",
            "[405   0   0   0   0   0   0   0   0   0   0] 1 20\n",
            "[425   0   0   0   0   0   0   0   0   0   0] 1 40\n",
            "[425 425 235 425 160   0   0   0   0   0   0] 1 60\n",
            "[425 425 485 425 410 425 110   0   0   0   0] 1 80\n",
            "[425 425 735 425 660 425 360 425 210 425 135] 1 100\n",
            "Episode:9 Score:-296 Total Steps:52\n",
            "[405 365  60   0   0   0   0   0   0   0   0] 1 20\n",
            "[425 365 310 425 135   0   0   0   0   0   0] 1 40\n",
            "[425 365 560 425 385   0   0   0   0   0   0] 1 60\n",
            "[425 365 810 425 635 235 160   0   0   0   0] 1 80\n",
            "Episode:10 Score:-349 Total Steps:46\n",
            "mean K:53.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4gUy3E7pTiG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbDWkUIyyQzc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}