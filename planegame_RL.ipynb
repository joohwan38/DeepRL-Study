{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "planegame_RL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1u42PkN7GL-w5Th6yhSA58T9zC2CLnVcV",
      "authorship_tag": "ABX9TyOU+/Cr1UfU8UTpZDRlo3dP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joohwan38/DeepRL-Study/blob/main/planegame_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK-5tkrHkvui",
        "outputId": "a9894341-fef4-497b-c161-f7aa8ecad302"
      },
      "source": [
        "!pip install stable_baselines3\n",
        "!pip install gym\n",
        "!pip install pygame"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.9.0+cu102)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->stable_baselines3) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->stable_baselines3) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->stable_baselines3) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->stable_baselines3) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->stable_baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable_baselines3) (2018.9)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6M3gmZukjXF",
        "outputId": "3e7f2284-53b0-4755-fef9-94f192fd192c"
      },
      "source": [
        "#import GYM stuff\n",
        "import gym \n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
        "\n",
        "#import helpers\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "#import Stable baselines stuff\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "#import pygame\n",
        "import pygame\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# pygame.quit()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.0.1 (SDL 2.0.14, Python 3.7.11)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3sxSSzpkoWq"
      },
      "source": [
        "pygame.init()\n",
        "#오브젝트 좌표, 이속, 사이즈 초기값 세팅\n",
        "class obj:\n",
        "    def __init__(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        self.move = 0\n",
        "    def put_img(self, a, b):\n",
        "        self.sx, self.sy = a, b\n",
        "\n",
        "#충돌 판정 (y/n)\n",
        "def crash(a, b):\n",
        "    if (a.x-b.sx <= b.x) and (b.x <= a.x+a.sx):\n",
        "        if (a.y-b.sy <= b.y) and (b.y <= a.y+a.sy):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "#커스텀 환경 세팅)\n",
        "\n",
        "class PlaneEnv(Env):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Actions 조작의 범위 설정\n",
        "        self.action_space = Discrete(3) \n",
        "        # 옵저베이션 설정 (x축, y축)\n",
        "        self.observation_space = MultiDiscrete([500, 500, 900, 500, 900, 500, 900, 500, 900, 500, 900])\n",
        "        # 시작 값 설정 (all zero)\n",
        "        self.state = np.zeros(11, dtype=int)\n",
        "        \n",
        "        self.ss = obj()\n",
        "        #비행선 사이즈\n",
        "        self.ss.put_img(50, 60)\n",
        "        \n",
        "        #비행선 시작 좌표\n",
        "        self.ss.x = 205 #round(size[0]/2 - self.ss.sx/2)\n",
        "        self.ss.y = 825 #size[1] -self.ss.sy - 15\n",
        "        self.ss.move = 20\n",
        "        \n",
        "        \n",
        "# 1프레임마다 일어날 일돌 \n",
        "    def step(self, action):\n",
        "        global done\n",
        "        \n",
        "        #프레임당 생존 시 리워드 2점 지급\n",
        "        reward =2\n",
        "\n",
        "        #액션에 따른 비행선의 x좌표 변경 0 왼쪽 / 1 오른쪽 / 2 제자리 - 화면 가장자리를 넘어가지 않게 설정\n",
        "        if action ==0:\n",
        "            self.ss.x -= self.ss.move\n",
        "            if self.ss.x <= 50:\n",
        "                self.ss.x = 50\n",
        "        elif action ==1:\n",
        "            self.ss.x += self.ss.move\n",
        "            if self.ss.x >= 425:\n",
        "                self.ss.x = 425\n",
        "        elif action ==2:\n",
        "            pass\n",
        "\n",
        "        #랜덤하게 적 비행체 생성 (프레임당 10% 확률로 생성)\n",
        "        if random.random() > 0.90:\n",
        "            aa = obj()\n",
        "            aa.put_img(40, 40)\n",
        "\n",
        "            # 5배의 확률로 내가 멈춰있는 x좌표 위에 적군 생성 / 나머지는 전역 생성\n",
        "            mylist = [self.ss.x, random.randrange(0,478)]\n",
        "            aa.x = random.choices(mylist, weights = [10, 2], k = 1)[0]\n",
        "            aa.y = 10\n",
        "            aa.move = 25\n",
        "            a_list.append(aa)\n",
        "\n",
        "        #레이더 설정    \n",
        "        for i in range(len(a_list)):\n",
        "            #y 좌표가 나보다 낮아지면 레이더 계산하지 않음\n",
        "            if a_list[i].y < 825:\n",
        "                pass\n",
        "            #비행체의 중심부 - 적비행체 중심부간 유클리디안 거리가 100픽셀 보다 낮을때 레이더 발동\n",
        "            #레이더에 걸리면, 100 나누기 둘사이 거리의 10분의 1만큼 감점 수식 (100 / (distance / 10))\n",
        "            elif (abs(self.ss.x+25 - a_list[i].x+20) * abs(self.ss.y+30 - a_list[i].y+20))**(1/2) < 100:\n",
        "                reward -= round(100/((abs(self.ss.x+25 - a_list[i].x+20) * abs(self.ss.y+30 - a_list[i].y+20))**(1/2)/10))\n",
        "\n",
        "        #충돌 시 감점 로직    \n",
        "        for i in range(len(a_list)):\n",
        "            a = a_list[i]\n",
        "            if crash(a, self.ss) == True:\n",
        "                done=True\n",
        "                reward -=400\n",
        "        \n",
        "        # 현재 프레임의 옵저베이션값 리턴 (state)\n",
        "        self.state[0] = self.ss.x\n",
        "        for i in range(len(a_list[:(len(self.state)-1)//2])):\n",
        "            self.state[2*i+1] = a_list[i].x\n",
        "            self.state[2*i+2] = a_list[i].y\n",
        "\n",
        "        #미사일의 좌표를 화면을 넘어가면 트래킹 하지 않게 삭제해주기\n",
        "        \n",
        "        d_list = []\n",
        "        for i in range(len(a_list)):\n",
        "            ea = a_list[i]\n",
        "            ea.y += ea.move\n",
        "            if ea.y >= size[1]:\n",
        "                d_list.append(i)\n",
        "        #미사일이 화면 밖으로 넘어갔다는 것은 회피를 위미하므로, 회피시 리워드 지급하기\n",
        "                reward +=30\n",
        "        for d in d_list:\n",
        "            del a_list[d]\n",
        "        \n",
        "        info = {}\n",
        "        \n",
        "        # Return step information\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        pass\n",
        "    \n",
        "    #게임리셋 (환경 초기화, 비행체 시작위치 초기화)\n",
        "    #적 비행체는 초기화 하지 않아도 됨 (프레임에서 생성하기 때문에 환경초기화 만으로 전체초기화 됨)\n",
        "    def reset(self):\n",
        "        # Reset shower temperature\n",
        "        self.state = np.zeros(11, dtype=int)\n",
        "        # Set shower length\n",
        "        self.ss.x = 205 #round(size[0]/2 - self.ss.sx/2)\n",
        "        self.ss.y = 825 #size[1] -self.ss.sy - 15\n",
        "        \n",
        "        return self.state"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doWurlgFlOiO"
      },
      "source": [
        "size = [500, 900]\n",
        "\n",
        "env=PlaneEnv()\n",
        "\n",
        "a_list=[]\n",
        "d_list=[]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dy8H9U-lR46",
        "outputId": "6a686fc2-289f-42a7-96d0-e072cb0f6e82"
      },
      "source": [
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    reward = 0\n",
        "    a_list=[]\n",
        "    d_list=[]\n",
        "    \n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "#         print(action, n_state, score, done)\n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "env.close()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:-368\n",
            "Episode:2 Score:-328\n",
            "Episode:3 Score:-328\n",
            "Episode:4 Score:-347\n",
            "Episode:5 Score:-445\n",
            "Episode:6 Score:-320\n",
            "Episode:7 Score:-294\n",
            "Episode:8 Score:-398\n",
            "Episode:9 Score:-304\n",
            "Episode:10 Score:-331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBj0rVM9lTlH"
      },
      "source": [
        "log_path = os.path.join('Training', 'Logs')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGwb0znMlVs5",
        "outputId": "d7ba9414-eae9-4528-9809-2d1518e3557a"
      },
      "source": [
        "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYRW71yMlXHL",
        "outputId": "8160c801-9ae2-4db1-bea6-0f4de0461a4a"
      },
      "source": [
        "model.learn(total_timesteps=500000)#, callback=eval_callback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to Training/Logs/PPO_2\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1        |\n",
            "|    ep_rew_mean     | -145     |\n",
            "| time/              |          |\n",
            "|    fps             | 531      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -230         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 313          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008485606 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.87e+04     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    value_loss           | 1e+05        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -165         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 276          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001231755 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.17e+04     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000152    |\n",
            "|    value_loss           | 1.05e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -170         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 260          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007856791 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.76e+04     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00051     |\n",
            "|    value_loss           | 8.27e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 1             |\n",
            "|    ep_rew_mean          | -103          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 251           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 40            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.9768558e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.09         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.94e+04      |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -1.8e-05      |\n",
            "|    value_loss           | 1.19e+05      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 1             |\n",
            "|    ep_rew_mean          | -185          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 245           |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 50            |\n",
            "|    total_timesteps      | 12288         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00026086098 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.09         |\n",
            "|    explained_variance   | 1.19e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 3.91e+04      |\n",
            "|    n_updates            | 50            |\n",
            "|    policy_gradient_loss | -0.000172     |\n",
            "|    value_loss           | 9.35e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -250         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 241          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001291775 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.13e+04     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -5.61e-05    |\n",
            "|    value_loss           | 8.99e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -196         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 238          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 68           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011986232 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.9e+04      |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.000939    |\n",
            "|    value_loss           | 1.08e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -127         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 236          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 77           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004660169 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.83e+04     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.000299    |\n",
            "|    value_loss           | 8.77e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -209        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 234         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 87          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013924267 |\n",
            "|    clip_fraction        | 0.0386      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.5e+04     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00459    |\n",
            "|    value_loss           | 6.55e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -229         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 233          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 96           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064449636 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.28e+04     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00589     |\n",
            "|    value_loss           | 9.3e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -167         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 232          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 105          |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073746573 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.5e+04      |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00153     |\n",
            "|    value_loss           | 9.63e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -196         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 115          |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010981597 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.72e+04     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | 1.62e-05     |\n",
            "|    value_loss           | 7.85e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -278         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 230          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 124          |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025355755 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.97        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.77e+04     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 0.00061      |\n",
            "|    value_loss           | 6.78e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -144         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 229          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 133          |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066198586 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.98e+04     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    value_loss           | 8.08e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -226        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 229         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 143         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010098631 |\n",
            "|    clip_fraction        | 0.0941      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.6e+04     |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | 0.00182     |\n",
            "|    value_loss           | 6.53e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -183        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 228         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 152         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004407866 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.02       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.85e+04    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00116    |\n",
            "|    value_loss           | 8.09e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -225        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 228         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 161         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006218534 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.07e+04    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.000501   |\n",
            "|    value_loss           | 7.34e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -180         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 227          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007333589 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.34e+04     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -9.6e-05     |\n",
            "|    value_loss           | 7.96e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -204        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 227         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 180         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007693399 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.995      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.72e+04    |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | 0.00485     |\n",
            "|    value_loss           | 7.17e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 1             |\n",
            "|    ep_rew_mean          | -210          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 227           |\n",
            "|    iterations           | 21            |\n",
            "|    time_elapsed         | 189           |\n",
            "|    total_timesteps      | 43008         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014351693 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.03         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.11e+04      |\n",
            "|    n_updates            | 200           |\n",
            "|    policy_gradient_loss | 0.000796      |\n",
            "|    value_loss           | 8.45e+04      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -231        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 226         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 198         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004916521 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.96e+04    |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00123    |\n",
            "|    value_loss           | 6.43e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -157        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 226         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 207         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001075356 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.02       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.52e+04    |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.000309   |\n",
            "|    value_loss           | 6.84e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -132         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 226          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 217          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076885833 |\n",
            "|    clip_fraction        | 0.138        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.972       |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.03e+04     |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | 0.00477      |\n",
            "|    value_loss           | 8.61e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 1             |\n",
            "|    ep_rew_mean          | -218          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 226           |\n",
            "|    iterations           | 25            |\n",
            "|    time_elapsed         | 226           |\n",
            "|    total_timesteps      | 51200         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00047715192 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.973        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 2.83e+04      |\n",
            "|    n_updates            | 240           |\n",
            "|    policy_gradient_loss | 0.00012       |\n",
            "|    value_loss           | 6.69e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -260         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 225          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 235          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049301186 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.984       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.09e+04     |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    value_loss           | 5.86e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1           |\n",
            "|    ep_rew_mean          | -153        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 225         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 245         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011321006 |\n",
            "|    clip_fraction        | 0.0563      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.832      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.84e+04    |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    value_loss           | 6.97e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1            |\n",
            "|    ep_rew_mean          | -166         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 225          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 254          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040630493 |\n",
            "|    clip_fraction        | 0.0501       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.845       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.57e+04     |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | 0.00198      |\n",
            "|    value_loss           | 7.58e+04     |\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6P7LIVcvFa9"
      },
      "source": [
        "#모델 저장하기\n",
        "plane_path = os.path.join('Training', 'Saved Models', 'evolution_10M_PPO')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a7eu8i6ldbU"
      },
      "source": [
        "model.save(plane_path)\n",
        "evaluate_policy(model, env, n_eval_episodes=100, render=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwFq5Uwgl280"
      },
      "source": [
        "# training_log_path = os.path.join(log_path, 'PPO_20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqd-TPWepGOE"
      },
      "source": [
        "model = PPO.load(plane_path, env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP0AWJtWpRJJ"
      },
      "source": [
        "#어떤식으로 움직이고, 어떤 값을 리턴하는지 확인해보기 (랜더링 없이)\n",
        "\n",
        "s_list=[]\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    reward = 0\n",
        "    a_list=[]\n",
        "    d_list=[]\n",
        "    \n",
        "    k=0\n",
        "    while not done:\n",
        "        k+=1\n",
        "        env.render()\n",
        "        action, _states = model.predict(obs)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "        if k %10 == 0:\n",
        "          print(obs, action, score)\n",
        "    s_list.append(k)\n",
        "    print('Episode:{} Score:{} Total Steps:{}'.format(episode, score, k))\n",
        "print('mean K:{}'.format(np.mean(s_list)))\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4gUy3E7pTiG"
      },
      "source": [
        "s_list=[]\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    reward = 0\n",
        "    a_list=[]\n",
        "    d_list=[]\n",
        "    \n",
        "    k=0\n",
        "    while not done:\n",
        "        k+=1\n",
        "        env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "        # if k %10 == 0:\n",
        "        #   print(obs, action, score)\n",
        "    s_list.append(k)\n",
        "    print('Episode:{} Score:{} Total Steps:{}'.format(episode, score, k))\n",
        "print('mean K:{}'.format(np.mean(s_list)))\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbDWkUIyyQzc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}